[
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/dynamic-programming/",
        "title": "Dynamic Programming",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.04.15",
        "body": "1. Rod cutting Three versions of rod cutting algorithms are implemented below.\n#include \u0026lt;stdlib.h\u0026gt; int cut_rod(int *p, int n) { if (n == 0) return 0; int i, q = -0x7fffffff; for (i = 0; i \u0026lt; n; ++i) { int temp_q = p[i] + cut_rod(p, n-i-1); q = temp_q \u0026gt; q ? temp_q : q; } return q; } int memoized_cut_rod_aux(int *p, int n, int *r) { if (n == 0) return 0; if (r[n-1] \u0026gt;= 0) return r[n-1]; int i, q = -0x7fffffff; for (i = 0; i \u0026lt; n; ++i) { int temp_q = p[i] + memoized_cut_rod_aux(p, n-i-1, r); q = temp_q \u0026gt; q ? temp_q : q; } r[n-1] = q; return q; } int memoized_cut_rod(int *p, int n) { int i, *r = malloc(sizeof(int)*n); for (i = 0; i \u0026lt; n; ++i) r[i] = -0x7fffffff; int result = memoized_cut_rod_aux(p, n, r); free(r); return result; } int bottom_up_cut_rod(int *p, int n) { int i, j, *r = malloc(sizeof(int)*n); for (i = 0; i \u0026lt; n; ++i) { int q = -0x7fffffff; for (j = 0; j \u0026lt;= i; ++j) { int temp_q = j == i ? p[j] : p[j] + r[i-j-1]; q = temp_q \u0026gt; q ? temp_q : q; } r[i] = q; } int result = r[n-1]; free(r); return result; } 2. Matrix-chain multiplication Four steps to use dynamic programming:\n Characterize the structure of an optimal solution. Recursively define the value of an optimal solution. Compute the value of an optimal solution. Construct an optimal solution from computed information.  3. Elements of dynamic programming There are two key ingredients that an optimization problem must in order for dynamic programming to apply:\n Optimal substructure: an optimal solution contains within it optimal solution to subproblems. Overlapping subproblems: a recursive algorithm revisits the same subproblems repeatly.  4. Longest common subsequence A program to find the longest common subsequence of two strings is implemented below.\n#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; void lcs_length(char *x, int nx, char *y, int ny, int *c, int *aux_c) { int i, j; for (i = 0; i \u0026lt;= nx; ++i) c[i*(ny+1)] = 0; for (j = 0; j \u0026lt;= ny; ++j) c[j] = 0; for (i = 1; i \u0026lt;= nx; ++i) for (j = 1; j \u0026lt;= ny; ++j) if (x[i-1] == y[j-1]) { c[i*(ny+1)+j] = c[(i-1)*(ny+1)+(j-1)] + 1; aux_c[i*(ny+1)+j] = 0; } else if (c[i*(ny+1)+(j-1)] \u0026gt; c[(i-1)*(ny+1)+j]) { c[i*(ny+1)+j] = c[i*(ny+1)+(j-1)]; aux_c[i*(ny+1)+j] = -1; } else { c[i*(ny+1)+j] = c[(i-1)*(ny+1)+j]; aux_c[i*(ny+1)+j] = 1; } return; } void print_lcs_aux(char *y, int ny, int *aux_c, int i, int j) { if (i == 0 || j == 0) return; if (aux_c[i*(ny+1)+j] == 0) { print_lcs_aux(y, ny, aux_c, i-1, j-1); printf(\u0026#34;%c\u0026#34;, y[j-1]); } else if (aux_c[i*(ny+1)+j] == 1) print_lcs_aux(y, ny, aux_c, i-1, j); else print_lcs_aux(y, ny, aux_c, i, j-1); return; } void print_lcs(char *x, int nx, char *y, int ny) { int *c = malloc(sizeof(int)*(nx+1)*(ny+1)); int *aux_c = malloc(sizeof(int)*(nx+1)*(ny+1)); lcs_length(x, nx, y, ny, c, aux_c); print_lcs_aux(y, ny, aux_c, nx, ny); printf(\u0026#34;\\n\u0026#34;); free(c); free(aux_c); return; } "
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/augmenting-data-structures/",
        "title": "Augmenting Data Structures",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.04.08",
        "body": "1. Dynamic order statistics Via adding a new attribute size in a red-black tree, we can determine any order statistic in \\(O(n)\\) time. The size refer to the number of nodes of the subtree whose root is the node. It is called order-statistic tree.\n2. How to augment a data structure  Choose an underlying data structure. Determine additional information to maintain in the underlying data structure. Verify that we can maintain the additional information for the basic modifying operations on the underlying data structure. Develop new operations.  "
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/red-black-trees/",
        "title": "Red-Black Trees",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.04.01",
        "body": "1. Properties of red-black trees A red-black tree is a binary search tree with one extra attribute per node: its color, which can be either RED or BLACK.\nAs a matter of convenience, we introduce a single sentinel and all leaf nodes point to this sentinel. A red-black tree satisfies the following properties:\n Every node is either red or black. The root is black. The sentinel is black. If a node is red, then both its children are black. For each node, all simple paths from the node to the sentinel contain the same number of black nodes.  Thus red-black trees ensure that no such path is more than twice as long as any other, so that the tree is balanced. A red-black tree with \\(n\\) nodes has height at most \\(2\\log(n+1)\\).\n2. Rotation, insertion and deletion To keep the properties while insertion and deletion, new operation rotation is necessary.\nAn interger red-black tree is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; struct object { int key; char color; struct object *p, *left, *right; }; struct red_black_tree { struct object *root, *sentinel; }; /*********** * search * ***********/ struct object *rb_tree_search(struct object *x, int k) { if (x == NULL || k == x-\u0026gt;key) return x; if (k \u0026lt; x-\u0026gt;key) return rb_tree_search(x-\u0026gt;left, k); else return rb_tree_search(x-\u0026gt;right, k); } struct object *rb_tree_min(struct object *x) { while (x-\u0026gt;left != NULL) x = x-\u0026gt;left; return x; } struct object *rb_tree_max(struct object *x) { while (x-\u0026gt;right != NULL) x = x-\u0026gt;right; return x; } struct object *rb_tree_successor(struct object *x) { if (x-\u0026gt;right != NULL) return rb_tree_min(x-\u0026gt;right); struct object *y = x-\u0026gt;p; while (y != NULL \u0026amp;\u0026amp; x == y-\u0026gt;right) {x = y; y = y-\u0026gt;p;} return y; } struct object *rb_tree_predecessor(struct object *x) { if (x-\u0026gt;left != NULL) return rb_tree_max(x-\u0026gt;left); struct object *y = x-\u0026gt;p; while (y != NULL \u0026amp;\u0026amp; x == y-\u0026gt;left) {x = y; y = y-\u0026gt;p;} return y; } /************* * rotation * *************/ void left_rotate(struct red_black_tree *T, struct object *x) { struct object *y = x-\u0026gt;right; x-\u0026gt;right = y-\u0026gt;left; if (y-\u0026gt;left != T-\u0026gt;sentinel) y-\u0026gt;left-\u0026gt;p = x; y-\u0026gt;p = x-\u0026gt;p; if (x-\u0026gt;p == T-\u0026gt;root) T-\u0026gt;root = y; else if (x-\u0026gt;p-\u0026gt;left == x) x-\u0026gt;p-\u0026gt;left = y; else x-\u0026gt;p-\u0026gt;right = y; y-\u0026gt;left = x; x-\u0026gt;p = y; return; } void right_rotate(struct red_black_tree *T, struct object *x) { struct object *y = x-\u0026gt;left; x-\u0026gt;left = y-\u0026gt;right; if (y-\u0026gt;right != T-\u0026gt;sentinel) y-\u0026gt;right-\u0026gt;p = x; y-\u0026gt;p = x-\u0026gt;p; if (x-\u0026gt;p == T-\u0026gt;root) T-\u0026gt;root = y; else if (x-\u0026gt;p-\u0026gt;left == x) x-\u0026gt;p-\u0026gt;left = y; else x-\u0026gt;p-\u0026gt;right = y; y-\u0026gt;right = x; x-\u0026gt;p = y; return; } /************** * insertion * **************/ void rb_insert_fixup(struct red_black_tree *T, struct object *z) { while (z-\u0026gt;p-\u0026gt;color == \u0026#39;r\u0026#39;) { if (z-\u0026gt;p == z-\u0026gt;p-\u0026gt;p-\u0026gt;left) { struct object *y = z-\u0026gt;p-\u0026gt;p-\u0026gt;right; if (y-\u0026gt;color == \u0026#39;r\u0026#39;) { z-\u0026gt;p-\u0026gt;color = \u0026#39;b\u0026#39;; y-\u0026gt;color = \u0026#39;b\u0026#39;; z-\u0026gt;p-\u0026gt;p-\u0026gt;color = \u0026#39;r\u0026#39;; z = z-\u0026gt;p-\u0026gt;p; } else { if (z == z-\u0026gt;p-\u0026gt;right) { z = z-\u0026gt;p; left_rotate(T, z); } z-\u0026gt;p-\u0026gt;color = \u0026#39;b\u0026#39;; z-\u0026gt;p-\u0026gt;p-\u0026gt;color = \u0026#39;r\u0026#39;; right_rotate(T, z-\u0026gt;p-\u0026gt;p); } } else { struct object *y = z-\u0026gt;p-\u0026gt;p-\u0026gt;left; if (y-\u0026gt;color == \u0026#39;r\u0026#39;) { z-\u0026gt;p-\u0026gt;color = \u0026#39;b\u0026#39;; y-\u0026gt;color = \u0026#39;b\u0026#39;; z-\u0026gt;p-\u0026gt;p-\u0026gt;color = \u0026#39;r\u0026#39;; z = z-\u0026gt;p-\u0026gt;p; } else { if (z == z-\u0026gt;p-\u0026gt;left) { z = z-\u0026gt;p; right_rotate(T, z); } z-\u0026gt;p-\u0026gt;color = \u0026#39;b\u0026#39;; z-\u0026gt;p-\u0026gt;p-\u0026gt;color = \u0026#39;r\u0026#39;; left_rotate(T, z-\u0026gt;p-\u0026gt;p); } } } return; } void rb_insert(struct red_black_tree *T, struct object *z) { struct object *x = T-\u0026gt;root, *y = T-\u0026gt;sentinel; while (x != T-\u0026gt;sentinel) { y = x; if (z-\u0026gt;key \u0026lt; x-\u0026gt;key) x = x-\u0026gt;left; else x = x-\u0026gt;right; } z-\u0026gt;p = y; if (y == T-\u0026gt;sentinel) T-\u0026gt;root = z; else if (z-\u0026gt;key \u0026lt; y-\u0026gt;key) y-\u0026gt;left = z; else y-\u0026gt;right = z; z-\u0026gt;left = T-\u0026gt;sentinel; z-\u0026gt;right = T-\u0026gt;sentinel; z-\u0026gt;color = \u0026#39;r\u0026#39;; rb_insert_fixup(T, z); return; } /************* * deletion * *************/ void rb_transplant(struct red_black_tree *T, struct object *u, struct object *v) { if (u-\u0026gt;p == T-\u0026gt;sentinel) T-\u0026gt;root = v; else if (u == u-\u0026gt;p-\u0026gt;left) u-\u0026gt;p-\u0026gt;left = v; else u-\u0026gt;p-\u0026gt;right = v; v-\u0026gt;p = u-\u0026gt;p; return; } void rb_delete_fixup(struct red_black_tree *T, struct object *x) { struct object *w; while (x != T-\u0026gt;sentinel \u0026amp;\u0026amp; x-\u0026gt;color == \u0026#39;b\u0026#39;) { if (x == x-\u0026gt;p-\u0026gt;left) { w = x-\u0026gt;p-\u0026gt;right; if (w-\u0026gt;color == \u0026#39;r\u0026#39;) { w-\u0026gt;color = \u0026#39;b\u0026#39;; x-\u0026gt;p-\u0026gt;color = \u0026#39;r\u0026#39;; left_rotate(T, x-\u0026gt;p); w = x-\u0026gt;p-\u0026gt;right; } if (w-\u0026gt;left-\u0026gt;color == \u0026#39;b\u0026#39; \u0026amp;\u0026amp; w-\u0026gt;right-\u0026gt;color == \u0026#39;b\u0026#39;) { w-\u0026gt;color = \u0026#39;r\u0026#39;; x = x-\u0026gt;p; } else { if (w-\u0026gt;right-\u0026gt;color == \u0026#39;b\u0026#39;) { w-\u0026gt;left-\u0026gt;color = \u0026#39;b\u0026#39;; w-\u0026gt;color = \u0026#39;r\u0026#39;; right_rotate(T, w); x = x-\u0026gt;p-\u0026gt;right; } w-\u0026gt;color = x-\u0026gt;p-\u0026gt;color; x-\u0026gt;p-\u0026gt;color = \u0026#39;b\u0026#39;; w-\u0026gt;right-\u0026gt;color = \u0026#39;b\u0026#39;; left_rotate(T, x-\u0026gt;p); x = T-\u0026gt;root; } } else { w = x-\u0026gt;p-\u0026gt;left; if (w-\u0026gt;color == \u0026#39;r\u0026#39;) { w-\u0026gt;color = \u0026#39;b\u0026#39;; x-\u0026gt;p-\u0026gt;color = \u0026#39;r\u0026#39;; right_rotate(T, x-\u0026gt;p); w = x-\u0026gt;p-\u0026gt;left; } if (w-\u0026gt;left-\u0026gt;color == \u0026#39;b\u0026#39; \u0026amp;\u0026amp; w-\u0026gt;right-\u0026gt;color == \u0026#39;b\u0026#39;) { w-\u0026gt;color = \u0026#39;r\u0026#39;; x = x-\u0026gt;p; } else { if (w-\u0026gt;right-\u0026gt;color == \u0026#39;b\u0026#39;) { w-\u0026gt;left-\u0026gt;color = \u0026#39;b\u0026#39;; w-\u0026gt;color = \u0026#39;r\u0026#39;; left_rotate(T, w); x = x-\u0026gt;p-\u0026gt;left; } w-\u0026gt;color = x-\u0026gt;p-\u0026gt;color; x-\u0026gt;p-\u0026gt;color = \u0026#39;b\u0026#39;; w-\u0026gt;right-\u0026gt;color = \u0026#39;b\u0026#39;; right_rotate(T, x-\u0026gt;p); x = T-\u0026gt;root; } } } x-\u0026gt;color = \u0026#39;b\u0026#39;; return; } void rb_delete(struct red_black_tree *T, struct object *z) { struct object *x, *y; y = z; char y_original_color = y-\u0026gt;color; if (z-\u0026gt;left == T-\u0026gt;sentinel) { x = z-\u0026gt;right; rb_transplant(T, z, z-\u0026gt;right); } else if (z-\u0026gt;right == T-\u0026gt;sentinel) { x = z-\u0026gt;left; rb_transplant(T, z, z-\u0026gt;left); } else { y = rb_tree_min(z-\u0026gt;right); y_original_color = y-\u0026gt;color; x = y-\u0026gt;right; if (y-\u0026gt;p != z) { rb_transplant(T, y, y-\u0026gt;right); y-\u0026gt;right = z-\u0026gt;right; y-\u0026gt;right-\u0026gt;p = y; } rb_transplant(T, z, y); y-\u0026gt;left = z-\u0026gt;left; y-\u0026gt;left-\u0026gt;p = y; y-\u0026gt;color = z-\u0026gt;color; } if (y_original_color == \u0026#39;b\u0026#39;) rb_delete_fixup(T, x); return; } 3. Other balanced search trees The idea of balancing a search tree is due to AVL trees in 1962. Another class of search trees, called 2-3 trees was introduced in 1970. Skip lists provide an alternative to balanced search trees.\n"
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/binary-search-trees/",
        "title": "Binary Search Trees",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.03.30",
        "body": "What is a binary search tree? A binary search tree is organized in a binary tree. The tree is represented by a linked data structure in which each node is an object. In addition to a key and satellite data, each object contains 3 more attributes: left, right and parent\nThe keys in a binary search tree are always stored in such a way as to satify that for each node in a binary search tree, the key of any node in its left subtree is smaller than its own key, and the key of any node in its right subtree is larger than its own key,\nQuerying a binary search tree Besides the SEARCH operation, binary search trees support queries as MINIMUM, MAXIMUM, SUCCESSOR and PREDECESSOR.\nInsertion and deletion To insert a new element to a binary search tree is relatively straightforward, but handling deletion when the node has both two children is somewhat more intricate.\nAn interger binary search tree is implemented below.\n#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; struct object { int key; struct object *p, *left, *right; }; struct binary_search_tree { struct object *root; }; void inorder_tree_walk(struct object *x) { if (x != NULL) { inorder_tree_walk(x-\u0026gt;left); printf(\u0026#34;%d \u0026#34;, x-\u0026gt;key); inorder_tree_walk(x-\u0026gt;right); } printf(\u0026#34;\\n\u0026#34;); return; } /*********** * search * ***********/ struct object *tree_search(struct object *x, int k) { if (x == NULL || k == x-\u0026gt;key) return x; if (k \u0026lt; x-\u0026gt;key) return tree_search(x-\u0026gt;left, k); else return tree_search(x-\u0026gt;right, k); } struct object *tree_min(struct object *x) { while (x-\u0026gt;left != NULL) x = x-\u0026gt;left; return x; } struct object *tree_max(struct object *x) { while (x-\u0026gt;right != NULL) x = x-\u0026gt;right; return x; } struct object *tree_successor(struct object *x) { if (x-\u0026gt;right != NULL) return tree_min(x-\u0026gt;right); struct object *y = x-\u0026gt;p; while (y != NULL \u0026amp;\u0026amp; x == y-\u0026gt;right) {x = y; y = y-\u0026gt;p;} return y; } struct object *tree_predecessor(struct object *x) { if (x-\u0026gt;left != NULL) return tree_max(x-\u0026gt;left); struct object *y = x-\u0026gt;p; while (y != NULL \u0026amp;\u0026amp; x == y-\u0026gt;left) {x = y; y = y-\u0026gt;p;} return y; } /************** * insertion * **************/ void tree_insert(struct binary_search_tree *T, struct object *z) { struct object *x = T-\u0026gt;root, *y = NULL; while (x != NULL) { y = x; if (z-\u0026gt;key \u0026lt; x-\u0026gt;key) x = x-\u0026gt;left; else x = x-\u0026gt;right; } z-\u0026gt;p = y; if (y == NULL) T-\u0026gt;root = z; else if (z-\u0026gt;key \u0026lt; y-\u0026gt;key) y-\u0026gt;left = z; else y-\u0026gt;right = z; return; } /************* * deletion * *************/ void transplant(struct binary_search_tree *T, struct object *u, struct object *v) { if (u-\u0026gt;p == NULL) T-\u0026gt;root = v; else if (u == u-\u0026gt;p-\u0026gt;left) u-\u0026gt;p-\u0026gt;left = v; else u-\u0026gt;p-\u0026gt;right = v; if (v != NULL) v-\u0026gt;p = u-\u0026gt;p; return; } void tree_delete(struct binary_search_tree *T, struct object *z) { if (z-\u0026gt;left == NULL) transplant(T, z, z-\u0026gt;right); else if (z-\u0026gt;right == NULL) transplant(T, z, z-\u0026gt;left); else { struct object *y = tree_min(z-\u0026gt;right); if (y-\u0026gt;p != z) { transplant(T, y, y-\u0026gt;right); y-\u0026gt;right = z-\u0026gt;right; y-\u0026gt;right-\u0026gt;p = y; } transplant(T, z, y); y-\u0026gt;left = z-\u0026gt;left; y-\u0026gt;left-\u0026gt;p = y; } } "
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/hash-tables/",
        "title": "Hash Tables",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.03.28",
        "body": "1. Direct-address tables To represent a dynamic set in which the keys are drawn from a small universe, we use a direct-address table, in which each slot corresponds to a key in the universe.\n2. Hash tables Hash tables is similar to direct-address tables. With direct addressing, an element with key \\(k\\) is stored in slot \\(k\\). With hashing, an element with key \\(k\\) is stored in slot \\(h(k)\\), where \\(h\\) is a hash function.\nHowever, two keys may hash to the same slot. We call this situation a collision. The simplest collision resolution technique is chaining. We place all elements that hash to the same slot into a linked list. Given a hash table with \\(m\\) slots storing \\(n\\) elements, a search takes average-case time \\(\\Theta(1+n/m)\\).\n3. Hash functions To map a key \\(k\\) into one of \\(m\\) slots, the hash function of division method is\n[h(k) = k \\mod m,]\nand that of multiplication method is\n[h(k) = \\lfloor m(kA \\mod 1) \\rfloor,]\nwhere \\(0 \u0026lt; A \u0026lt; 1\\).\nUniversal hashing is to choose the hash function randomly in a way that is independent of the keys that are actually going to be stored.\nAn integer hash table with chaining and division hash function is implemented below.\n#include \u0026lt;stdlib.h\u0026gt;#define HASH_TABLE_SIZE 1024  struct object { int key; struct object *prev, *next; }; struct hash_table { struct object *T[HASH_TABLE_SIZE]; }; struct object *hash_search(struct hash_table *h, int k) { int index = k / HASH_TABLE_SIZE; struct object *re = h-\u0026gt;T[index]; while (re != NULL \u0026amp;\u0026amp; re-\u0026gt;key != k) re = re-\u0026gt;next; return re; } void hash_insert(struct hash_table *t, struct object *x) { int index = x-\u0026gt;key / HASH_TABLE_SIZE; x-\u0026gt;next = t-\u0026gt;T[index]; if (t-\u0026gt;T[index] != NULL) t-\u0026gt;T[index]-\u0026gt;prev = x; x-\u0026gt;prev = NULL; t-\u0026gt;T[index] = x; return; } void hash_delete(struct hash_table *h, struct object *x) { int index = x-\u0026gt;key / HASH_TABLE_SIZE; if (x-\u0026gt;prev != NULL) x-\u0026gt;prev-\u0026gt;next = x-\u0026gt;next; else h-\u0026gt;T[index] = x-\u0026gt;next; if (x-\u0026gt;next != NULL) x-\u0026gt;next-\u0026gt;prev = x-\u0026gt;prev; return; } 4. Open addressing Another collision resolution technique is open addressing. In open addressing, each table entry contains an element, NULL or DELETED. To insert an element, we probe the table until finding an empty slot. The probe sequence is generated by a hash function,\n[\\{h(k, 0), h(k, 1), \\dots, h(k, m-1)\\},]\nand is required to be a permutation. To search an element, we probe the table until finding the element or a NULL. To delete an element, we mark the corresponding slot with DELETED.\nThere are three commonly used techniques to compute the probe sequence.\n Linear probing: \\(h(k, i) = (h'(k) + i) \\mod m\\), Quadratic probing: \\(h(k, i) = (h'(k) + c_1i + c_2i^2) \\mod m\\), Double hashing: \\(h(k, i) = (h'(k) + h''(k)) \\mod m\\),  where \\(h'(k), h''(k)\\) are ordinary hash functions.\nLet \\(\\alpha = n/m\\), the expected number of probes in an unsuccessful search is \\(1/(1-\\alpha)\\), and that in a successful search is \\(\\frac{1}{\\alpha} \\ln \\frac{1}{1-\\alpha}\\).\n5. Perfect hashing If the set of keys is static, \\(O(1)\\) memory accesses can be satisfied with perfect hashing technique. The structure is similar to hash tables with chaining. Instead of making a linked list of the keys hashing to the same slot, we use a small secondary hash table. By choosing the hash function carefully, we can guarantee that there are no collisions.\nThe size of the secondary hash table is the square of the number of keys hashing to this slot. However the total size of hash table is \\(O(n)\\).\n"
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/elementary-data-structures/",
        "title": "Elementary Data Structures",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.03.17",
        "body": "1. Stacks and queues Stacks and queues are dynamic sets. The stack implements a last-in, first-out policy, while the queue implements a first-in, first-out policy.\nAn integer stack of size 1024 is implemented below.\n#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; struct stack { int a[1024]; int top; }; void push(struct stack *s, int x) { if (s-\u0026gt;top == 1023) { fprintf(stderr, \u0026#34;Overflow!\\n\u0026#34;); exit(1); } ++s-\u0026gt;top; s-\u0026gt;a[s-\u0026gt;top] = x; return; } int pop(struct stack *s) { if (s-\u0026gt;top == -1) { fprintf(stderr, \u0026#34;Underflow!\\n\u0026#34;); exit(1); } --s-\u0026gt;top; return s-\u0026gt;a[s-\u0026gt;top+1]; } An integer queue of size 1024 is implemented below.\n#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; struct queue { int a[1024]; int head, tail; }; void enqueue(struct queue *q, int x) { q-\u0026gt;a[q-\u0026gt;tail] = x; q-\u0026gt;tail = (q-\u0026gt;tail + 1) % 1024; if (q-\u0026gt;tail == q-\u0026gt;head) { fprintf(stderr, \u0026#34;Overflow!\\n\u0026#34;); exit(1); } return; } int dequeue(struct queue *q) { if (q-\u0026gt;head == q-\u0026gt;tail) { fprintf(stderr, \u0026#34;Underflow!\\n\u0026#34;); exit(1); } int x = q-\u0026gt;a[q-\u0026gt;head]; q-\u0026gt;head = (q-\u0026gt;head + 1) % 1024; return x; } 2. Linked lists A linked list is a linear-arranged data structure in which the order is determined by a pointer in each object.\nAn integer double linked list with a sentinel is implemented below.\nstruct object { int key; struct object *prev, *next; }; struct linked_list { struct object *sentinel; }; struct object* list_search(struct linked_list *L, int k) { struct object *re = L-\u0026gt;sentinel-\u0026gt;next; while (re != L-\u0026gt;sentinel \u0026amp;\u0026amp; re-\u0026gt;key != k) re = re-\u0026gt;next; return re; } void list_insert(struct linked_list *L, struct object *x) { x-\u0026gt;next = L-\u0026gt;sentinel-\u0026gt;next; L-\u0026gt;sentinel-\u0026gt;next-\u0026gt;prev = x; x-\u0026gt;prev = L-\u0026gt;sentinel; L-\u0026gt;sentinel-\u0026gt;next = x; return; } void list_delete(struct linked_list *L, struct object *x) { x-\u0026gt;prev-\u0026gt;next = x-\u0026gt;next; x-\u0026gt;next-\u0026gt;prev = x-\u0026gt;prev; return; } 3. Implementing pointers and objects We can use three arrays to implement a double linked list. For an index i, key[i], next[i] and prev[i] represent an object in the double linked list.\nA single array can also be used to implement a linked list just like how operating systems manage the computer memory. We can use a linked list with only next attribute to implement a stack, which we call the free list, to record which objects are free.\n4. Representing rooted trees The representation of a binary is just like that of a linked list. The difference is objects of trees have two childs.\n"
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/medians-and-order-statistics/",
        "title": "Medians and Order Statistics",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.03.01",
        "body": "The \\(i\\)th order statistic of a set of \\(n\\) elements is the \\(i\\)th smallest element.\nA selection problem is to select the \\(i\\)th order statistic from a set of \\(n\\) distinct numbers.\n1. Minimum and maximum Every element except the winner must lose once in a comparison. Hence \\(n-1\\) comparisions are necessary to determine the minimum. The algorithm is implemented below.\nint minimum(int *a, int n) { int i, min = a[0]; for (i = 1; i \u0026lt; n; ++i) if (min \u0026gt; a[i]) min = a[i]; return min; } If we want to find the minimum and maximum simultaneously, only \\(3\\lfloor n/2 \\rfloor\\) comparisions are necessary. The algorithm is implemented below.\nvoid min_and_max(int *a, int n, int *mm) { int i = (n % 2 == 1)?1:0; mm[0] = a[0]; mm[1] = a[0]; for (; i \u0026lt; n-1; i += 2) if (a[i] \u0026lt; a[i+1]) { if (a[i] \u0026lt; mm[0]) mm[0] = a[i]; if (a[i+1] \u0026gt; mm[1]) mm[1] = a[i+1]; } else { if (a[i+1] \u0026lt; mm[0]) mm[0] = a[i+1]; if (a[i] \u0026gt; mm[1]) mm[1] = a[i]; } return; } 2. Selection in expected linear time The randomized select algorithm is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; int partition(int *a, int b, int e) { int ae = a[e]; int i = b - 1, j = b; for (; j \u0026lt; e; ++j) { if (a[j] \u0026lt;= ae) { ++i; int temp = a[i]; a[i] = a[j]; a[j] = temp; } } a[e] = a[i+1]; a[i+1] = ae; return i + 1; } int randomized_partition(int *a, int b, int e) { int i = rand() % (e - b + 1) + b; int temp = a[i]; a[i] = a[e]; a[e] = temp; return partition(a, b, e); } int randomized_select_r(int *a, int b, int e, int i) { if (b == e) return a[b]; int m = randomized_partition(a, b, e); if (i == m - b) return a[b]; else if (i \u0026lt; m - b) return randomized_select_r(a, b, m-1, i); else return randomized_select_r(a, m+1, e, i-(m-b)-1); } int randomized_select(int *a, int n, int i) { return randomized_select_r(a, 0, n-1, i); } The worst-case running time is \\(\\Theta(n^2)\\). If the elements are distinct, the expected running time is \\(O(n)\\).\n"
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/sorting-in-linear-time/",
        "title": "Sorting in Linear Time",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.02.26",
        "body": "1. Lower bounds for sorting Any comparision sort algorithm requires \\(\\Omega(n \\log n)\\) comparisions int the worst case.\n2. Counting sort The counting sort algorithm is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; void counting_sort(int *a, int n, int k) { int *b = (int *) malloc(sizeof(int)*n); int *c = (int *) malloc(sizeof(int)*k); int i; for (i = 0; i \u0026lt; k; ++i) c[i] = 0; for (i = 0; i \u0026lt; n; ++i) ++c[a[i]]; for (i = 1; i \u0026lt; k; ++i) c[i] += c[i-1]; for (i = n-1; i \u0026gt;= 0; --i) { b[c[a[i]]-1] = a[i]; --c[a[i]]; } for (i = 0; i \u0026lt; n; ++i) a[i] = b[i]; free(b); free(c); return; } 3. Radix sort The radix sort algorithm is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; void radix_sort(int *a, int n, int d) { int *b = (int *) malloc(sizeof(int)*n); int *c = (int *) malloc(sizeof(int)*10); int i, j, e = 1; for (i = 0; i \u0026lt; d; ++i) { for (j = 0; j \u0026lt; 10; ++j) c[j] = 0; for (j = 0; j \u0026lt; n; ++j) ++c[a[j]/e%10]; for (j = 1; j \u0026lt; 10; ++j) c[j] += c[j-1]; for (j = n-1; j \u0026gt;= 0; --j) { b[c[a[j]/e%10]-1] = a[j]; --c[a[j]/e%10]; } for (j = 0; j \u0026lt; n; ++j) a[j] = b[j]; e *= 10; } free(b); free(c); return; } "
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/quicksort/",
        "title": "Quicksort",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.02.26",
        "body": "1. Description of quicksort The quicksort algorithm is implemented below.\nint partition(int *a, int b, int e) { int ae = a[e]; int i = b - 1, j = b; for (; j \u0026lt; e; ++j) { if (a[j] \u0026lt;= ae) { ++i; int temp = a[i]; a[i] = a[j]; a[j] = temp; } } a[e] = a[i+1]; a[i+1] = ae; return i + 1; } void quicksort_r(int *a, int b, int e) { if (b \u0026lt; e) { int m = partition(a, b, e); quicksort_r(a, b, m-1); quicksort_r(a, m+1, e); } return; } void quicksort(int *a, int n) { quicksort_r(a, 0, n-1); return; } 2. Performance of quicksort The worst-case behavior occurs when the partitioning routine produces one subproblem with \\(n-1\\) elements and one with 0 elements. And the running time is \\(\\Theta(n^2)\\).\nThe expected running time is \\(\\Theta(n\\log n)\\).\n3. A randomized version of quicksort The randomized_quicksort algorithm is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; int randomized_partition(int *a, int b, int e) { int i = rand() % (e - b + 1) + b; int temp = a[i]; a[i] = a[e]; a[e] = temp; return partition(a, b, e); } void randomized_quicksort_r(int *a, int b, int e) { if (b \u0026lt; e) { int m = partition(a, b, e); randomized_quicksort_r(a, b, m-1); randomized_quicksort_r(a, m+1, e); } return; } void randomized_quicksort(int *a, int n) { randomized_quicksort_r(a, 0, n-1); return; } "
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/heapsort/",
        "title": "Heapsort",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.02.24",
        "body": "1. Heaps The heap data structure is an array that can be viewed as nearly complete binary tree. The tree is completely filled on all levels except possibly the lowest, which is filled from the left up to a point. The parent index of the \\(i\\)th element is \\(\\lceil i/2 \\rceil -1\\), the left child index is \\(2i+1\\), and the right child index is \\(2i+2\\).\nThere are two kinds of heaps, max-heap and min-heap. In a max-heap, for every node other than the root, the value is not larger than that of its parent. In a min-heap, for every node other than the root, the value is not smaller than that of its parent.\n2. Maintaining the heap property The algorithm is implemented below.\nvoid max_heapify(int *a, int n, int i) { int l = 2 * i + 1, r = 2 * i + 2; int temp, temp_i = i; if (l \u0026lt; n \u0026amp;\u0026amp; a[l] \u0026gt; a[i]) temp_i = l; if (r \u0026lt; n \u0026amp;\u0026amp; a[r] \u0026gt; a[temp_i]) temp_i = r; if (temp_i != i) { temp = a[i]; a[i] = a[temp_i]; a[temp_i] = temp; max_heapify(a, n, temp_i); } return; } 3. Building a heap The algorithm is implemented below.\nvoid build_max_heap(int *a, int n) { int i = n / 2 - 1; for (; i \u0026gt;= 0; --i) max_heapify(a, n, i); return; } 4. The heapsort algorithm The algorithm is implemented below.\nvoid heap_sort(int *a, int n) { int i, temp; build_max_heap(a, n); for (i = n - 1; i \u0026gt; 0; --i) { temp = a[0]; a[0] = a[i]; a[i] = temp; max_heapify(a, i, 0); } return; } The running time of heapsort is \\(O(n\\log n)\\).\n"
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/probabilistic-analysis-and-randomized-algorithms/",
        "title": "Probabilistic Analysis and Randomized Algorithms",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2021.02.22",
        "body": "1. The hiring problem We have used worst-case analysis in the previous analysis of problems. Another approach is probabilistic analysis, in which we analyze algorithms via average-case running time.\n2. Indicator random variables The indicator random variable associated with event \\(A\\) is defined as [I(A) = \\begin{cases} 1 \u0026amp; \\text{if \\(A\\) occurs,} \\\\\n0 \u0026amp; \\text{if \\(A\\) does not occur.} \\end{cases}]\nUsing indicator random variables, we obtain the average-case hiring cost of the hiring problem is \\(O(c \\log n)\\).\n3. Randomized algorithms In order to use probabilistic analysis, we need to know the distribution of the inputs. In many cases, we know very little about it. Yet we often use probability and randomness as a tool for algorithm design and analysis. An algorithm is randomized if its behavior is determined not only by its input but also by values produced by a random-number generator.\nThe permuting arrays algorithms are implemented below.\n#include \u0026lt;stdlib.h\u0026gt; void permute_by_sorting(int *a, int n) { int *p = malloc(sizeof(int)*n); int i, j, temp_p, temp_a; for (i = 0; i \u0026lt; n; ++i) p[i] = rand(); for (i = 1; i \u0026lt; n; ++i) { temp_p = p[i]; temp_a = a[i]; j = i - 1; while (j \u0026gt;= 0 \u0026amp;\u0026amp; p[j] \u0026gt; temp_p) { p[j+1] = p[j]; a[j+1] = a[j]; j -= 1; } p[j+1] = temp_p; a[j+1] = temp_a; } free(p); return; } void randomize_in_place(int *a, int n) { int i, j, temp; for (i = 0; i \u0026lt; n; ++i) { j = rand() % n; temp = a[i]; a[i] = a[j]; a[j] = temp; } return; } "
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/divide-and-conquer/",
        "title": "Divide-and-Conquer",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2020.08.17",
        "body": "1. The maximum-subarray problem The algorithm is implemented below.\nvoid find_maximum_subarray(int *a, int *low, int *high) { if (*low == *high) return; int mid = (*low + *high) / 2, i; // left recursion  int low1 = *low, high1 = mid; find_maximum_subarray(a, \u0026amp;low1, \u0026amp;high1); int max1 = 0; for (i = low1; i \u0026lt;= high1; ++i) max1 += a[i]; // right recursion  int low2 = mid+1, high2 = *high; find_maximum_subarray(a, \u0026amp;low2, \u0026amp;high2); int max2 = 0; for (i = low2; i \u0026lt;= high2; ++i) max2 += a[i]; // subarray across mid point  // left part  int low3, sum_left = 0, max3_left = a[mid]; for (i = mid; i \u0026gt;= *low; --i) { sum_left += a[i]; if (sum_left \u0026gt;= max3_left) {low3 = i; max3_left = sum_left;} } // right part  int high3, sum_right = 0, max3_right = a[mid+1]; for (i = mid+1; i \u0026lt;= *high; ++i) { sum_right += a[i]; if (sum_right \u0026gt;= max3_right) {high3 = i; max3_right = sum_right;} } // merge  int max3 = max3_left + max3_right; // return  if (max1 \u0026gt;= max2 \u0026amp;\u0026amp; max1 \u0026gt;= max3) {*low = low1; *high = high1;} else if (max2 \u0026gt;= max3) {*low = low2; *high = high2;} else {*low = low3; *high = high3;} return; } 2. Strassen\u0026rsquo;s algorithm for matrix multiplication The square matrix multiply algorithm is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; int* square_matrix_multiply(int *a, int *b, int d) { int i, j, k; int *c = malloc(sizeof(int)*d*d); for (i = 0; i \u0026lt; d; ++i) for (j = 0; j \u0026lt; d; ++j) { int index_c = d * i + j; *(c+ index_c) = 0; for (k = 0; k \u0026lt; d; ++k) { int index_a = d * i + k, index_b = d * k + j; *(c + index_c) += *(a + index_a) * *(b + index_b); } } return c; } The simple divide-and-conquer version is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; int* square_matrix_multiply_recursive( int *a, int ax1, int ay1, int ax2, int ay2, int *b, int bx1, int by1, int bx2, int by2, int d) { int n = ax2 - ax1 + 1; int *c = malloc(sizeof(int)*n*n); if (n == 1) { *c = *(a + (ax1 * d + ay1)) * *(b + (bx1 *d + by1)); } else { int m = n / 2; int a11x1 = ax1, a11y1 = ay1, a11x2 = ax1+m-1, a11y2 = ay1+m-1; int a12x1 = ax1, a12y1 = ay1+m, a12x2 = ax1+m-1, a12y2 = ay2; int a21x1 = ax1+m, a21y1 = ay1, a21x2 = ax2, a21y2 = ay1+m-1; int a22x1 = ax1+m, a22y1 = ay1+m, a22x2 = ax2, a22y2 = ay2; int b11x1 = bx1, b11y1 = by1, b11x2 = bx1+m-1, b11y2 = by1+m-1; int b12x1 = bx1, b12y1 = by1+m, b12x2 = bx1+m-1, b12y2 = by2; int b21x1 = bx1+m, b21y1 = by1, b21x2 = bx2, b21y2 = by1+m-1; int b22x1 = bx1+m, b22y1 = by1+m, b22x2 = bx2, b22y2 = by2; int *c111 = square_matrix_multiply_recursive( a, a11x1, a11y1, a11x2, a11y2, b, b11x1, b11y1, b11x2, b11y2, d); int *c112 = square_matrix_multiply_recursive( a, a12x1, a12y1, a12x2, a12y2, b, b21x1, b21y1, b21x2, b21y2, d); int *c121 = square_matrix_multiply_recursive( a, a11x1, a11y1, a11x2, a11y2, b, b12x1, b12y1, b12x2, b12y2, d); int *c122 = square_matrix_multiply_recursive( a, a12x1, a12y1, a12x2, a12y2, b, b22x1, b22y1, b22x2, b22y2, d); int *c211 = square_matrix_multiply_recursive( a, a21x1, a21y1, a21x2, a21y2, b, b11x1, b11y1, b11x2, b11y2, d); int *c212 = square_matrix_multiply_recursive( a, a22x1, a22y1, a22x2, a22y2, b, b21x1, b21y1, b21x2, b21y2, d); int *c221 = square_matrix_multiply_recursive( a, a21x1, a21y1, a21x2, a21y2, b, b12x1, b12y1, b12x2, b12y2, d); int *c222 = square_matrix_multiply_recursive( a, a22x1, a22y1, a22x2, a22y2, b, b22x1, b22y1, b22x2, b22y2, d); int i, j; for (i = 0; i \u0026lt; m; ++i) for (j = 0; j \u0026lt; m; ++j) { *(c+(i*n+j)) = *(c111+(i*m+j)) + *(c112+(i*m+j)); *(c+(i*n+j+m)) = *(c121+(i*m+j)) + *(c122+(i*m+j)); *(c+((i+m)*n+j)) = *(c211+(i*m+j)) + *(c212+(i*m+j)); *(c+((i+m)*n+j+m)) = *(c221+(i*m+j)) + *(c222+(i*m+j)); } } return c; } The Strassen\u0026rsquo;s method is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; int* square_matrix_multiply_strassens_method( int *a, int ax1, int ay1, int ax2, int ay2, int d1, int *b, int bx1, int by1, int bx2, int by2, int d2) { int n = ax2 - ax1 + 1; int *c = malloc(sizeof(int)*n*n); if (n == 1) { *c = *(a + (ax1 * d1 + ay1)) * *(b + (bx1 *d2 + by1)); } else { int m = n / 2; int a11x1 = ax1, a11y1 = ay1, a11x2 = ax1+m-1, a11y2 = ay1+m-1; int a12x1 = ax1, a12y1 = ay1+m, a12x2 = ax1+m-1, a12y2 = ay2; int a21x1 = ax1+m, a21y1 = ay1, a21x2 = ax2, a21y2 = ay1+m-1; int a22x1 = ax1+m, a22y1 = ay1+m, a22x2 = ax2, a22y2 = ay2; int b11x1 = bx1, b11y1 = by1, b11x2 = bx1+m-1, b11y2 = by1+m-1; int b12x1 = bx1, b12y1 = by1+m, b12x2 = bx1+m-1, b12y2 = by2; int b21x1 = bx1+m, b21y1 = by1, b21x2 = bx2, b21y2 = by1+m-1; int b22x1 = bx1+m, b22y1 = by1+m, b22x2 = bx2, b22y2 = by2; int *s1 = malloc(sizeof(int)*m*m); int *s2 = malloc(sizeof(int)*m*m); int *s3 = malloc(sizeof(int)*m*m); int *s4 = malloc(sizeof(int)*m*m); int *s5 = malloc(sizeof(int)*m*m); int *s6 = malloc(sizeof(int)*m*m); int *s7 = malloc(sizeof(int)*m*m); int *s8 = malloc(sizeof(int)*m*m); int *s9 = malloc(sizeof(int)*m*m); int *s10 = malloc(sizeof(int)*m*m); int i, j; for (i = 0; i \u0026lt; m; ++i) for (j = 0; j \u0026lt; m; ++j) { *(s1+(i*m+j)) = *(b+(b12x1+i)*d2+b12y1+j) - *(b+(b22x1+i)*d2+b22y1+j); *(s2+(i*m+j)) = *(a+(a11x1+i)*d1+a11y1+j) + *(a+(a12x1+i)*d1+a12y1+j); *(s3+(i*m+j)) = *(a+(a21x1+i)*d1+a21y1+j) + *(a+(a22x1+i)*d1+a22y1+j); *(s4+(i*m+j)) = *(b+(b21x1+i)*d2+b21y1+j) - *(b+(b11x1+i)*d2+b11y1+j); *(s5+(i*m+j)) = *(a+(a11x1+i)*d1+a11y1+j) + *(a+(a22x1+i)*d1+a22y1+j); *(s6+(i*m+j)) = *(b+(b11x1+i)*d2+b11y1+j) + *(b+(b22x1+i)*d2+b22y1+j); *(s7+(i*m+j)) = *(a+(a12x1+i)*d1+a12y1+j) - *(a+(a22x1+i)*d1+a22y1+j); *(s8+(i*m+j)) = *(b+(b21x1+i)*d2+b21y1+j) + *(b+(b22x1+i)*d2+b22y1+j); *(s9+(i*m+j)) = *(a+(a11x1+i)*d1+a11y1+j) - *(a+(a21x1+i)*d1+a21y1+j); *(s10+(i*m+j)) = *(b+(b11x1+i)*d2+b11y1+j) + *(b+(b12x1+i)*d2+b12y1+j); } int *p1 = square_matrix_multiply_strassens_method( a, a11x1, a11y1, a11x2, a11y2, d1, s1, 0, 0, m-1, m-1, m); int *p2 = square_matrix_multiply_strassens_method( s2, 0, 0, m-1, m-1, m, b, b22x1, b22y1, b22x2, b22y2, d2); int *p3 = square_matrix_multiply_strassens_method( s3, 0, 0, m-1, m-1, m, b, b11x1, b11y1, b11x2, b11y2, d2); int *p4 = square_matrix_multiply_strassens_method( a, a22x1, a22y1, a22x2, a22y2, d1, s4, 0, 0, m-1, m-1, m); int *p5 = square_matrix_multiply_strassens_method( s5, 0, 0, m-1, m-1, m, s6, 0, 0, m-1, m-1, m); int *p6 = square_matrix_multiply_strassens_method( s7, 0, 0, m-1, m-1, m, s8, 0, 0, m-1, m-1, m); int *p7 = square_matrix_multiply_strassens_method( s9, 0, 0, m-1, m-1, m, s10, 0, 0, m-1, m-1, m); for (i = 0; i \u0026lt; m; ++i) for (j = 0; j \u0026lt; m; ++j) { *(c+(i*n+j)) = *(p5+(i*m+j)) + *(p4+(i*m+j)) - *(p2+(i*m+j)) + *(p6+(i*m+j)); *(c+(i*n+j+m)) = *(p1+(i*m+j)) + *(p2+(i*m+j)); *(c+((i+m)*n+j)) = *(p3+(i*m+j)) + *(p4+(i*m+j)); *(c+((i+m)*n+j+m)) = *(p5+(i*m+j)) + *(p1+(i*m+j)) - *(p3+(i*m+j)) - *(p7+(i*m+j)); } } return c; } 3. The substitution method for solving recurrences The substitution method comprises two steps:\n Guess the form of the solution. Use mathematical induction to find the constants and show that the solution works.  Subtle skill: Sometimes you might correctly guess the solution of a recurrence, but some how the math fails to work out. For example, consider the recurrence,\n[T(n) = T(\\lfloor n/2 \\rfloor) + T(\\lceil n/2 \\rceil) + 1. ]\nWe guess the solution is \\(T(n) = O(n)\\). We obtain,\n[T(n) \\leq c\\lfloor n/2 \\rfloor + c\\lceil n/2 \\rfloor + 1 = cn + 1,]\nwhich does not implies \\(T(n) \\leq cn\\). If our guess is \\(T(n) \\leq cn - d\\), we have\n[T(n) \\leq cn -2d + 1.]\nwhich implies that \\(T(n) \\leq cn -d\\) as long as \\(d \\geq 1\\).\n4. The recursion-tree method for solving recurrences A recursion tree is usually used to generate a good guess. You can then verify by the substitution method. When using a recursion tree to generate a good guess, you can often tolerate a small amount of \u0026ldquo;sloppiness\u0026rdquo;.\n5. The master method for solving recurrences Let \\(a \\geq 1\\) and \\(b \u0026gt; 1\\) be constants, let \\(f(n)\\) be a function, and let \\(T(n)\\) be defined on the nonnegative integers by the recurrence [T(n) = aT(n/b) + f(n),] where we interpret \\(n/b\\) to mean either \\(\\lfloor n/b \\rfloor\\) or \\(\\lceil n/b \\rceil\\). Then \\(T(n)\\) has the following asymptotic bounds:\n If \\(f(n) = O(n^{\\log_b a - \\epsilon})\\) for some constant \\(\\epsilon \u0026gt; 0\\), then \\(T(n) = \\Theta(n^{\\log_b a})\\). If \\(f(n) = \\Theta(n^{\\log_b a})\\), then \\(T(n) = \\Theta(n^{\\log_b a}\\lg n)\\). If \\(f(n) = \\Omega(n^{\\log_b a + \\epsilon})\\) for some constant \\(\\epsilon \u0026gt; 0\\), and if \\(af(n/b) \\leq cf(n)\\) for some constant \\(c \u0026lt; 1\\) and all sufficiently large \\(n\\), then \\(T(n) = \\Theta(f(n))\\).  "
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/growth-of-functions/",
        "title": "Growth of Functions",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2020.07.20",
        "body": "1. Asymptotic notation \\(\\Theta\\)-notation: \\(f(n) \\in \\Theta(g(n))\\) if there exist positive constants \\(c_1, c_2, n_0\\), such that for all \\(n \\geq n_0\\),\n[0 \\leq c_1 g(n) \\leq f(n) \\leq c_2 g(n)]\n\\(O\\)-notation: \\(f(n) \\in O(g(n))\\) if there exist positive constants \\(c, n_0\\), such that for all \\(n \\geq n_0\\),\n[0 \\leq f(n) \\leq c g(n)]\n\\(\\Omega\\)-notation: \\(f(n) \\in \\Omega(g(n))\\) if there exist positive constants \\(c, n_0\\), such that for all \\(n \\geq n_0\\),\n[0 \\leq c g(n) \\leq f(n)]\n\\(o\\)-notation: \\(f(n) \\in o(g(n))\\) if for all positive constant \\(c\\), there exists \\(n_0\\), such that for all \\(n \\geq n_0\\),\n[0 \\leq f(n) \u0026lt; c g(n)]\n\\(\\omega\\)-notation: \\(f(n) \\in \\omega(g(n))\\) if for all positive constant \\(c\\), there exists \\(n_0\\), such that for all \\(n \\geq n_0\\),\n[0 \\leq c g(n) \u0026lt; f(n)]\n2. Standard notations and common functions 2.1 Monotonicity A function \\(f(n)\\) is monotonically increasing, if \\(m \\leq n\\) implies \\(f(m) \\leq f(n)\\).\nA function \\(f(n)\\) is monotonically decreasing, if \\(m \\leq n\\) implies \\(f(m) \\geq f(n)\\).\n2.2 Floors and ceilings [x-1 \u0026lt; \\lfloor x \\rfloor \\leq x \\leq \\lceil x \\rceil \u0026lt; x+1] [\\lceil n/2 \\rceil + \\lfloor n/2 \\rfloor = n] [\\left\\lceil \\frac{\\lceil x/a \\rceil}{b} \\right\\rceil = \\left\\lceil \\frac{x}{ab} \\right\\rceil] [\\left\\lfloor \\frac{\\lfloor x/a \\rfloor}{b} \\right\\rfloor = \\left\\lfloor \\frac{x}{ab} \\right\\rfloor] [\\left\\lceil \\frac{a}{b} \\right\\rceil \\leq \\frac{a+b-1}{b}] [\\left\\lfloor \\frac{a}{b} \\right\\rfloor \\geq \\frac{a-b+1}{b}]\n2.3 Modular arithmetic The value of \\(a \\mod n\\) is the residue of the quotient \\(a/n\\).\n2.4 Polynomials A polynomial in \\(n\\) of degree \\(d\\) is a function of the form\n[p(n) = \\sum_{i=0}^d a_i n^i]\n2.5 Exponentials [f(n) = a^n]\nThe Taylor series of \\(e^x\\),\n[e^x = \\sum_{i=0}^\\infty \\frac{x^i}{i!}]\n2.6 Logarithms Denote \\(\\lg n = \\log_2 n\\) and \\(\\ln n = \\log_e n\\).\n2.7 Factorials Stirling\u0026rsquo;s approximation,\n[n! = \\sqrt{2\\pi n}(\\frac{n}{e})^n(1 + \\Theta(\\frac{1}{n}))]\n2.8 Functional iteration [f^{(i)}(n) = f(f(\\dots f(n)))]\n2.9 The iteration logarithm function [\\lg^* n = \\min \\{i : \\lg^{(i)} n \\leq 1\\}]\n"
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/getting-started/",
        "title": "Getting Started",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2020.05.18",
        "body": "1. Insertion sort Insertion sort is implemented below.\nvoid insertion_sort(int *a, int n) { int i, j, temp; for (i = 1; i \u0026lt; n; ++i) { temp = a[i]; j = i - 1; while (j \u0026gt;= 0 \u0026amp;\u0026amp; a[j] \u0026gt; temp) { a[j+1] = a[j]; j -= 1; } a[j+1] = temp; } return; } We use loop invariants to proof the correctness of our algorithm. A loop invariant includes three parts:\n It\u0026rsquo;s true prior to the first iteration. If it\u0026rsquo;s true before an iteration, it remain true before the next iteration. When the loop terminates, the invariant give us a useful property.  2. Analyzing algorithms The worst-case running time of insertion sort is \\(\\Theta(n^2)\\).\n3. Designing algorithms We use the idea of divide-and-conquer to design a sort algorithm, merge sort. It is implemented below.\n#include \u0026lt;stdlib.h\u0026gt; void merge(int *a, int b, int m, int e) { int i, j, k; int *a1 = (int *) malloc(sizeof(int)*(m-b+2)); for (i = b; i \u0026lt;= m; ++i) a1[i-b] = a[i]; a1[m-b+1] = 0x7FFFFFFF; int *a2 = (int *) malloc(sizeof(int)*(e-m+1)); for (j = m+1; j \u0026lt;= e; ++j) a2[j-m-1] = a[j]; a2[e-m] = 0x7FFFFFFF; i = 0; j = 0; for (k = b; k \u0026lt;= e; ++k) { if (a1[i] \u0026lt;= a2[j]) {a[k] = a1[i]; ++i;} else {a[k] = a2[j]; ++j;} } free(a1); free(a2); return; } void merge_sort_r(int *a, int b, int e) { if (e \u0026gt; b) { int m = (e + b) / 2; merge_sort(a, b, m); merge_sort(a, m+1, e); merge(a, b, m, e); } return; } void merge_sort(int *a, int n) { merge_sort_r(a, 0, n-1); return; } The worst-case running time of merge sort is \\(\\Theta(n\\log n)\\).\n"
    }
,
    {
        "ref": "https://binzhang-u5f6c.github.io/posts/the-role-of-algorithms-in-computing/",
        "title": "The Role of Algorithms in Computing",
        "section": "posts",
        "tags": ["algorithms"],
        "date" : "2020.05.04",
        "body": "1. Algorithms An algorithm is any well-defined computational procedure. A data structure is a way to store and organize data in order to facilitate access and modifications.\n2. Algorithms as a technology Since computers are not infinitely fast, and memory is not free, efficient algorithms are important. A usual measure of efficiency is speed.\n"
    }
]
